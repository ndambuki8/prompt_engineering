{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBlqY4lLnJVU",
        "outputId": "e74bb010-94e7-4953-d2d9-339cecb23371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.81.0\n",
            "    Uninstalling openai-1.81.0:\n",
            "      Successfully uninstalled openai-1.81.0\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "%pip install openai==0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jsmgj7zwWL5"
      },
      "source": [
        "# Giving clear instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4C4VErZfoWDr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "\n",
        "openai.api_key = \"API_KEY\"\n",
        "\n",
        "system_message = \"\"\"\n",
        "You are an AI assistant that helps humans by generating tutorials given a text.\n",
        "You will be provided with a text. If the text contains any kind of instructions on how to procees with something, generate a tutorial in a bullet list.\n",
        "Otherwise, inform the user that the text does not contain any instructions.\n",
        "\n",
        "Text:\n",
        "\"\"\"\n",
        "\n",
        "instructions = \"\"\"\n",
        "To prepare the known sauce from Genova, Italy, you can start by toasting the pine nuts to then coarsely chop them in a kitchen mortar and season with basil and garlic.\n",
        "Then, add half of the oil in the kitchen mortar and season with salt and pepper.\n",
        "Finally, transfer the pesto to a bowl and stir in the grated Parmesan cheese.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\": system_message},\n",
        "        {\"role\":\"user\", \"content\":instructions}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANImTSCAqkCD",
        "outputId": "ae4795ce-9f23-4198-e244-75c71d297d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- How to make Genovese sauce:\n",
            "    1. Start by toasting the pine nuts in a pan until they are lightly browned.\n",
            "    2. Coarsely chop the toasted pine nuts using a kitchen mortar and pestle.\n",
            "    3. Add basil leaves and garlic cloves to the mortar and continue to grind until well combined.\n",
            "    4. Gradually pour in half of the olive oil while mixing the ingredients in the mortar.\n",
            "    5. Season the mixture with salt and pepper to taste.\n",
            "    6. Transfer the pesto sauce from the mortar to a bowl.\n",
            "    7. Stir in the grated Parmesan cheese until well incorporated.\n",
            "    8. Your Genovese sauce is now ready to be served with your favorite pasta or dish. Enjoy!\n"
          ]
        }
      ],
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJhEofjzq_rw",
        "outputId": "4bce6ba3-3b00-4700-cef4-6066d05fe2c4"
      },
      "outputs": [],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdVtm2MWr3Bv",
        "outputId": "cd6bfca1-e1f6-4bad-9bb0-0b64dfd1fff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The text does not contain any instructions.\n"
          ]
        }
      ],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\": system_message},\n",
        "        {\"role\":\"user\", \"content\":\"the sun is shining and dogs are running on the beach.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PopijnGxwaAg"
      },
      "source": [
        "# Split complex tasks into subtasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ccrPw11lxUK4"
      },
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are an AI assistant that summarizes articles.\n",
        "To complete this task, do the following subtasks:\n",
        "\n",
        "Read the provided article context comprehensively and identify the main topic and keypoints.\n",
        "Generate a paragraph summary of the current article context that captures the essential information and conveys the main idea.\n",
        "Print each step of the process.\n",
        "\n",
        "Article:\n",
        "\"\"\"\n",
        "\n",
        "article = \"\"\"\n",
        "Recurrent neural networks, long short-term memory and gated recurrent neural networks\n",
        "in particular, have been firmly established as state of the art approaches in sequence modeling and\n",
        "transduction problems such as language modeling and machine translation. Numerous\n",
        "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
        "architectures.\n",
        "Recurrent models typically factor computation along the symbol positions of the input and output\n",
        "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
        "states ht, as a function of the previous hidden state ht-1 and the input for position t. This inherently\n",
        "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
        "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
        "significant improvements in computational efficiency through factorization tricks and conditional\n",
        "computation, while also improving model performance in case of the latter. The fundamental\n",
        "constraint of sequential computation, however, remains.\n",
        "Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
        "the input or output sequences. In all but a few cases, however, such attention mechanisms\n",
        "are used in conjunction with a recurrent network.\n",
        "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
        "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
        "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
        "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lZ0ETwr0wnHW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = \"API_KEY\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\": system_message},\n",
        "        {\"role\":\"user\", \"content\":article},\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmlrSrUOyER_",
        "outputId": "c19a09ed-7171-4fe5-dcdf-d491e55fdfd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Main Topic and Key Points\n",
            "Main Topic: The article discusses the use of recurrent neural networks, specifically long short-term memory and gated recurrent neural networks, in sequence modeling and transduction problems. It also introduces the Transformer model as an alternative approach that relies solely on an attention mechanism without recurrence.\n",
            "\n",
            "Key Points:\n",
            "- Recurrent neural networks are widely used in sequence modeling and transduction problems like language modeling and machine translation.\n",
            "- While recurrent models are effective, they face challenges in parallelization due to their sequential nature.\n",
            "- Attention mechanisms have enhanced sequence modeling by capturing dependencies without limitations on distance.\n",
            "- The article introduces the Transformer model, which uses attention mechanisms exclusively, allowing for more parallelization and achieving state-of-the-art translation quality in a relatively short training time.\n",
            "\n",
            "Step 2: Article Summary\n",
            "The article discusses the significance of recurrent neural networks, particularly long short-term memory and gated recurrent neural networks, in sequence modeling and transduction tasks like language modeling and machine translation. It highlights challenges faced by recurrent models in parallelization due to their sequential nature. Attention mechanisms are noted for improving modeling by capturing dependencies without distance limitations. Introducing the Transformer model, the article presents an alternative approach that relies solely on attention mechanisms for global dependency connections, allowing for increased parallelization and achieving high translation quality with shorter training times on multiple GPUs.\n"
          ]
        }
      ],
      "source": [
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSo3PwMDyk-j"
      },
      "source": [
        "# Asking for justification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSH-k45Ny0lK",
        "outputId": "29d7284d-84dd-45c4-fd57-2768c473c49f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The answer to this riddle is a clock. \n",
            "\n",
            "A clock has a face with numbers or markings to indicate the time, and two hands (hour and minute hands) that move to show the current time. Although a clock has hands, it does not have arms or legs, making it the perfect solution to this riddle. \n",
            "\n",
            "The reasoning behind this answer is that the description aligns perfectly with the features of a clock - face, hands, but no arms or legs.\n"
          ]
        }
      ],
      "source": [
        "system_message = \"\"\"\n",
        "You are an AI assistant specialized in solving riddles.\n",
        "Given a riddle, solve it the best way you can.\n",
        "Provide a clear justification of your answer and the reasoning behind it.\n",
        "\n",
        "Riddle:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "riddle = \"\"\"\n",
        "What has a face ans two hands, but no arms or legs?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":system_message},\n",
        "        {\"role\":\"user\", \"content\":riddle}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJXx39Kp0C6w"
      },
      "source": [
        "# Generate many outputs, then use the model to pick the best one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are an AI assistant specialized in solving riddles.\n",
        "Given a riddle, you have to generate three answers to the riddle.\n",
        "For each answer, be specific about the reasoning you made.\n",
        "Then among the three answers, select the one that is most plausible given the riddle.\n",
        "\n",
        "Riddle:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "riddle = \"\"\"\n",
        "What has a face ans two hands, but no arms or legs?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":system_message},\n",
        "        {\"role\":\"user\", \"content\":riddle}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Repeat instructions at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are a sentiment analyzer. You classsify conversations into three categories: positive, negative or neutral.\n",
        "Return only the sentiment, in lowercase and without punctuation.\n",
        "\n",
        "Conversation:\n",
        "{conversation}\n",
        "Remember to return only the sentiment, in lowercase and without punctuation.\n",
        "\"\"\"\n",
        "\n",
        "conversation = \"\"\"\n",
        "Customer: Hi, I need some help with my order.\n",
        "AI agent: Hello, welcome to our online store. I'm an AI agent and I'm here to assist you.\n",
        "Customer: I ordered a pair of shoes yesterday, but I haven't received a confirmation email yet. Can you check the status of my order?\n",
        "AI agent: Sure, I can help you with that. Can you please provide me with your order number and email address?\n",
        "Customer: Yes, my order number is 123456789 and my email is john.doe@example.com.\n",
        "AI agent: Thank you. I have found your order in our system. It looks like your order is still being processed and it will be shipped soon. You should receive a confirmation email within 24 hours.\n",
        "Customer: OK, thank you for the information. How long will it take for the shoes to arrive?\n",
        "AI agent: You're welcome. According to our shipping policy, it will take about 3 to 5 business days for the shoes to arrive at your address. You can track your order online using the tracking number that will be sent to your email once your order is shipped.\n",
        "Customer: Alright, sounds good. Thank you for your help.\n",
        "AI agent: It's my pleasure. Is there anything else I can do for you today?\n",
        "Customer: No, that's all. Have a nice day.\n",
        "AI agent: Thank you for choosing our online store. Have a nice day too. Goodbye.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":system_message},\n",
        "        {\"role\":\"user\", \"content\":conversation},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using delimiters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## >>>> ====== ---- #######   ```````````"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are a Python expert who produces Python code as per the user's request.\n",
        "\n",
        "===>START EXAMPLE\n",
        "\n",
        "---User Query---\n",
        "Give me a function to print a string of text\n",
        "\n",
        "---User Output---\n",
        "Below you can find the described function:\n",
        "```def my_print(text):\n",
        "      return print(text)\n",
        "```\n",
        "\n",
        "<===END EXAMPLE\n",
        "\"\"\"\n",
        "\n",
        "query = \"generate a Python functino to calcuate the nth Fibonacci number\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":system_message},\n",
        "        {\"role\":\"user\", \"content\":query}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Few-shot approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\"\"\n",
        "You are an AI marketing assistant. You help users to create taglines for new product names.\n",
        "Given a product name, produce a tagline similar to the following examples:\n",
        "\n",
        "Peak Pursuit - Conquer heights with comfort\n",
        "Summit Steps - Your Partner for Every Ascent\n",
        "Crag Conquerors - Step Up, Stand Tall\n",
        "\n",
        "\n",
        "Product name:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "product_name = 'Elevation Embrace'\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":system_message},\n",
        "        {\"role\":\"user\", \"content\":product_name}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### example2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are a binary classifier for sentiment analysis.\n",
        "Given a text, based on its sentiment you classify it into one of two categories: positive or negative.\n",
        "\n",
        "You can use the following texts as examples:\n",
        "\n",
        "Text: \"I love this product! It's fantastic and works perfectly.\"\n",
        "Positive\n",
        "\n",
        "Text: \"I'm really disappointed with the quality of the food.\"\n",
        "Negative\n",
        "\n",
        "Text: \"This is the best day of my life!\"\n",
        "Positive\n",
        "\n",
        "Text: \"I can't stand the noise in this restaurant.\"\n",
        "Negative\n",
        "\n",
        "ONLY return the sentiment as output (without punctuation).\n",
        "\n",
        "Text:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "text = \"The concert was amazing! The band was incredible!\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":system_message},\n",
        "        {\"role\":\"user\", \"content\":text}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### example3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as numpy\n",
        "import pandas as pandas\n",
        "\n",
        "df = pd.read_csv('movie.csv', encoding='utf-8')\n",
        "df['label'] = df['label'].replace({0:'Negative', 1: 'Positive'})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sample(n=10, random_state=42)\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
