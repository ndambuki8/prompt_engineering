{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b19d823",
   "metadata": {},
   "source": [
    "## LangChain's Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b199e2a",
   "metadata": {},
   "source": [
    "### Models and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAP_API_KEY\"]\n",
    "\n",
    "llm = openAI()\n",
    "print(llm('tell me a joke'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Sentence: {sentence}\n",
    "Translation in {language}:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\n",
    "\n",
    "print(prompt.format(sentence = \"the cat is on the table\", language=\"spanish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30b31d",
   "metadata": {},
   "source": [
    "### Data Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7d08e",
   "metadata": {},
   "source": [
    "#### Document loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d2cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    ['Name', 'Age', 'City'],\n",
    "    ['John', 25, 'New York'],\n",
    "    ['Emily', 28, 'Los Angeles'],\n",
    "    ['Michael', 22, 'Chicago']\n",
    "]\n",
    "\n",
    "# File name\n",
    "file_name = 'sample.csv'\n",
    "\n",
    "# Write data to csv file\n",
    "with open(file_name, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(data)\n",
    "\n",
    "print(f'Sample CSV file \"{file_name}\" generated and saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='sample.csv')\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c4016",
   "metadata": {},
   "source": [
    "#### Document splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e6ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sentences about mountains and nature\n",
    "content = \"\"\"Amidst the serene landscape, towering mountains stand as majestic guardians of nature's beauty.\n",
    "The cris mountain air carries whispers of tranquility, while the rustling leaves compose a symphony of wilderness.\n",
    "Nature's palette paints the mountains with hues of green and brown, creating an awe-inspiring sight to behold.\n",
    "As the sub ruses, it casts a golden glow on the mountain peaks, illuminating a world untouched and wild.\"\"\"\n",
    "\n",
    "# File name\n",
    "file_name = 'mountain.txt'\n",
    "\n",
    "# Write content to text file\n",
    "with open(file_name, 'w') as txtfile:\n",
    "    txtfile.write(content)\n",
    "\n",
    "#print(f'sample text file \"{file_name}\" generated and saved')\n",
    "\n",
    "with open('mountain.txt') as f:\n",
    "    mountain = f.read()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([mountain])\n",
    "print(texts[0])\n",
    "print(texts[1])\n",
    "print(texts[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8310f69",
   "metadata": {},
   "source": [
    "#### Text embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-ada-002')\n",
    "\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Good morning!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"I want to report an accident\",\n",
    "        \"Sorry to hear that. May I have your name?\",\n",
    "        \"Sure, Mario Rossi.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Embed documents:\")\n",
    "print(f\"Number of vector: {len(embeddings)}; Dimension of each vector: {len(embeddings[0])}\")\n",
    "\n",
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "\n",
    "print(\"Embed query:\")\n",
    "print(f'Dimensions of the vector: {len(embedded_query)}')\n",
    "print(f'Sample of the first 5 elements of the vector: {embedded_query[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b02cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the conversation in a text file\n",
    "# List of dialogue lines\n",
    "dialogue_lines = [\n",
    "    \"Good morning!\",\n",
    "    \"Oh, hello!\",\n",
    "    \"I want to report an accident\",\n",
    "    \"Sorry to hear that. May I have your name?\",\n",
    "    \"Sure, Mario Rossi.\"\n",
    "]\n",
    "\n",
    "# File name\n",
    "file_name = 'dialogue.txt'\n",
    "\n",
    "# Write dialogue lines to text file\n",
    "with open(file_name, 'w') as txtfile:\n",
    "    for line in dialogue_lines:\n",
    "        txtfile.write(line + '\\n')\n",
    "\n",
    "print(f'Dialogue text file \"{file_name}\" generated and saved.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3151bbc",
   "metadata": {},
   "source": [
    "#### Vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb27474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "\n",
    "raw_documents = TextLoader('dialogue.txt').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=50, chunk_overlap=0, separator=\"\\n\",)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the reason for calling?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c99fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a2941",
   "metadata": {},
   "source": [
    "#### Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9dc770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "retriever = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b85daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "query = \"What was the reason for the call?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb7332",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a60b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=OpenAI(temperature=0))\n",
    "memory.save_context({\"input\":\"hi, I'm looking for some ideas to write an essay in AI\"}, {\"output\": \"hello, what about writing on LLMs?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d7498",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConversationSummaryMemory.save_context?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da396159",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c607c",
   "metadata": {},
   "source": [
    "#### Simpe Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f18c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "template = \"\"\"Sentence: {sentence}\n",
    "Translation in {language}:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "llm_chain.predict(sentence=\"the cat is on the table\", language=\"spanish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea480c9",
   "metadata": {},
   "source": [
    "#### Router chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f353461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "itinerary_template = \"\"\"You are a vacation itinerary assistant. \\\n",
    "You help customers finding the best destinations and itinerary. \\\n",
    "You help customer screating an optimized itinerary based on their preferences.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "restaurant_template = \"\"\"You are a restaurant booking assitant. \\\n",
    "You check with customers number of guests and food preferences. \\\n",
    "You pay attention whether there are special conditions to take into account.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"itinerary\",\n",
    "        \"description\": \"Good for creating itinerary\",\n",
    "        \"prompt_template\": itinerary_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"restaurant\",\n",
    "        \"description\": \"Good for help custors at restaurant\",\n",
    "        \"prompt_template\": restaurant_template,\n",
    "    },\n",
    "]\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destination_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destination_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f171ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(\"I'm planning a trip from Milan to Venice by car. What can I visit in between?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(\"I want to book a table for tonight\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01271aa9",
   "metadata": {},
   "source": [
    "#### Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# This is an LLMChain to write a synopsis given a title of a play\n",
    "llm = OpenAI(tenperature=0)\n",
    "template = \"\"\"You are comedian. Generate a joke on the following {topic}\n",
    "Joke:\"\"\"\n",
    "\n",
    "prompt_Template = PromptTemplate(input_variables=[\"topic\"], template=template)\n",
    "joke_chain =LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"You are a translator. Given a text input, translate it to {language}\n",
    "Translation:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"language\"], template=template)\n",
    "translator_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[joke_chain, translator_chain], verbose=True)\n",
    "translated_joke = overall_chain.run(\"Cats and Dogs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
