{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20735697",
   "metadata": {},
   "source": [
    "## Conversational App for Itinerary Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#from langchain import HuggingFaceHub\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "#retrieving api key\n",
    "key=os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c385b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagePlaceHolder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bfe872",
   "metadata": {},
   "source": [
    "### Sample bot with no memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94853668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that helps the user to plan an optimized itinerary.\"),\n",
    "    HumanMessage(content=\"I'm going to Rome for 2 days, what can I visit?\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chat(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da2e44",
   "metadata": {},
   "source": [
    "### Adding Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, verbose=True, memory=memory\n",
    ")\n",
    "\n",
    "conversation.run(\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20363387",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.run(\"what is the most iconic place in Rome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.run(\"What kind of other events?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9863771",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40efc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagePlaceHolder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#LLM\n",
    "repo_id = 'databricks/dolly-v2-3b'\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id = repo_id, model_kwargs={\"temperature\":0.5, \"max_length\":1000}\n",
    ")\n",
    "\n",
    "#Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a helpful assistant that help the user to plan an optimized itinerary.\"\n",
    "        ),\n",
    "        # The`variable_name` here is what must align with memory\n",
    "        MessagePlaceHolder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_message=True)\n",
    "conversation = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ea5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    query = input('you: ')\n",
    "    if query == 'q':\n",
    "        break\n",
    "    output = conversation({\"'question\": query})\n",
    "    print('User ', query)\n",
    "    print('AI System: ', output['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2262d",
   "metadata": {},
   "source": [
    "### Adding non parametric knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a52553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 200\n",
    ")\n",
    "\n",
    "raw_documents = PyPDFLoader('italy_travel.pdf').load()\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2763de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key= 'chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(llm,  retriever=db.as_retriever(), memory=memory, verbose=True)\n",
    "qa_chain.run({'question':'Give me some review about the Pantheon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cdad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "custom_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone quuestion.\n",
    "If you cannot find the answer in the document provided, ignore the document and answer anyway.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    condense_question_prompt = CUSTOM_QUESTION_PROMPT,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "qa_chain.run({'question':'What can I visit in India?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a7dc1",
   "metadata": {},
   "source": [
    "### Agent with memory for conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    db.as_retriever(),\n",
    "    \"italy_travel\",\n",
    "    \"Searches and returns documents regarding Italy\"\n",
    ")\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "agent_executor = create_conversational_retrieval_agent(llm, tools, memory_key='chat_history', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1247a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor({'input':\"hi, I'm Vale\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d94ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor({\"input\":\"Tell me something about Pantheon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent_executor({\"input\":\"What can I visit in India in 3 days?\"})\n",
    "output['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caccfffe",
   "metadata": {},
   "source": [
    "### Adding external tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.tools imporort BaseTool, StructureTool, Tool, tool\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.environ[\"SERPAPI_API_KEY\"]\n",
    "\n",
    "search = SerpAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    create_retriever_tool(\n",
    "        db.as_retriever(),\n",
    "        \"italy_travel\",\n",
    "        \"Searches and returns documents regarding Italy.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent_executor = create_conversational_retrieval_agent(llm, tools, memory_key=\"chat_history\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor({\"input\":\"What can I visit in India in 3 days?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01081064",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor({\"input\": \"What is the current weather in Delhi?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor({\"input\":\"I'm travelling to Italy, can you give me some suggestions of the main attractions?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
